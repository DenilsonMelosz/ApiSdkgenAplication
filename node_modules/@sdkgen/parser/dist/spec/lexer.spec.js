"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const lexer_1 = require("../src/lexer");
const token_1 = require("../src/token");
function itLexes(source, expectedTokens) {
    test(`lexes ${JSON.stringify(source)} as [${expectedTokens.join(", ")}]`, () => {
        const lexer = new lexer_1.Lexer(source);
        let tokens = [];
        for (;;) {
            const token = lexer.nextToken();
            if (!token) {
                break;
            }
            tokens.push(token);
        }
        tokens = tokens.map((token, i) => (expectedTokens[i] instanceof token_1.IdentifierToken ? token.maybeAsIdentifier() : token));
        expect(tokens.join(", ")).toEqual(expectedTokens.join(", "));
    });
}
function itDoesntLex(source, message) {
    test(`doesn't lex ${JSON.stringify(source)}`, () => {
        const lexer = new lexer_1.Lexer(source);
        expect(() => {
            while (lexer.nextToken()) {
                //
            }
        }).toThrowError(message);
    });
}
describe(lexer_1.Lexer, () => {
    itLexes("", []);
    itLexes("type", [new token_1.TypeKeywordToken()]);
    itDoesntLex("23", 'Unexpected character "2" at -:1:1');
    itDoesntLex("2a", 'Unexpected character "2" at -:1:1');
    itLexes("type2", [new token_1.IdentifierToken("type2")]);
    itLexes("aaa", [new token_1.IdentifierToken("aaa")]);
    itLexes("...aaa", [new token_1.SpreadSymbolToken(), new token_1.IdentifierToken("aaa")]);
    itLexes("a b c", [new token_1.IdentifierToken("a"), new token_1.IdentifierToken("b"), new token_1.IdentifierToken("c")]);
    itLexes("aa_bb", [new token_1.IdentifierToken("aa_bb")]);
    itLexes("type type", [new token_1.TypeKeywordToken(), new token_1.TypeKeywordToken()]);
    itLexes("enum", [new token_1.EnumKeywordToken()]);
    itLexes("error", [new token_1.ErrorKeywordToken()]);
    itLexes("import", [new token_1.ImportKeywordToken()]);
    itLexes("Get", [new token_1.IdentifierToken("Get")]);
    itLexes("fn", [new token_1.FnKeywordToken()]);
    itLexes("enuma", [new token_1.IdentifierToken("enuma")]);
    itLexes("errorh", [new token_1.IdentifierToken("errorh")]);
    for (const kw of ["enum", "type", "error", "import", "get", "function", "fn", "true", "false"]) {
        itLexes(kw, [new token_1.IdentifierToken(kw)]);
    }
    for (const primitive of lexer_1.Lexer.PRIMITIVES) {
        itLexes(primitive, [new token_1.PrimitiveTypeToken(primitive)]);
        itLexes(primitive, [new token_1.IdentifierToken(primitive)]);
        itLexes(`${primitive}a`, [new token_1.IdentifierToken(`${primitive}a`)]);
    }
    itLexes("err", [new token_1.IdentifierToken("err")]);
    itLexes("{", [new token_1.CurlyOpenSymbolToken()]);
    itLexes("{{", [new token_1.CurlyOpenSymbolToken(), new token_1.CurlyOpenSymbolToken()]);
    itLexes("}{", [new token_1.CurlyCloseSymbolToken(), new token_1.CurlyOpenSymbolToken()]);
    itLexes(" } { ", [new token_1.CurlyCloseSymbolToken(), new token_1.CurlyOpenSymbolToken()]);
    itLexes("({!:?,=})", [
        new token_1.ParensOpenSymbolToken(),
        new token_1.CurlyOpenSymbolToken(),
        new token_1.ExclamationMarkSymbolToken(),
        new token_1.ColonSymbolToken(),
        new token_1.OptionalSymbolToken(),
        new token_1.CommaSymbolToken(),
        new token_1.EqualSymbolToken(),
        new token_1.CurlyCloseSymbolToken(),
        new token_1.ParensCloseSymbolToken(),
    ]);
    itLexes(" [][] ", [new token_1.ArraySymbolToken(), new token_1.ArraySymbolToken()]);
    itLexes("nice[]", [new token_1.IdentifierToken("nice"), new token_1.ArraySymbolToken()]);
    itLexes("nice\n[]", [new token_1.IdentifierToken("nice"), new token_1.ArraySymbolToken()]);
    itDoesntLex("[", "Unexpected end of file");
    itLexes("type Str string", [new token_1.TypeKeywordToken(), new token_1.IdentifierToken("Str"), new token_1.PrimitiveTypeToken("string")]);
    itLexes('"ab"', [new token_1.StringLiteralToken("ab")]);
    itLexes('""', [new token_1.StringLiteralToken("")]);
    itLexes('"aa\\nbb"', [new token_1.StringLiteralToken("aa\nbb")]);
    itLexes('"aa\\bb"', [new token_1.StringLiteralToken("aabb")]);
    itLexes('"\'"', [new token_1.StringLiteralToken("'")]);
    itLexes('"\\n\\t\\""', [new token_1.StringLiteralToken('\n\t"')]);
    itLexes('"/* */"', [new token_1.StringLiteralToken("/* */")]);
    itLexes("//hmmm", []);
    itLexes("x//hmmm", [new token_1.IdentifierToken("x")]);
    itLexes("a//hmmm\nb", [new token_1.IdentifierToken("a"), new token_1.IdentifierToken("b")]);
    itLexes("a  //  hmmm  \n  b", [new token_1.IdentifierToken("a"), new token_1.IdentifierToken("b")]);
    itLexes("// héýça\n z", [new token_1.IdentifierToken("z")]);
    itDoesntLex("2", 'Unexpected character "2" at -:1:1');
    itDoesntLex("\n2", 'Unexpected character "2" at -:2:1');
    itDoesntLex("//\n2", 'Unexpected character "2" at -:2:1');
    itDoesntLex("//\n 2", 'Unexpected character "2" at -:2:2');
    itDoesntLex("//x\n2", 'Unexpected character "2" at -:2:1');
    itDoesntLex("//x\n 2", 'Unexpected character "2" at -:2:2');
    itDoesntLex("/*\n*/3", 'Unexpected character "3" at -:2:3');
    itDoesntLex("/*\n\n\n\n*/ 2", 'Unexpected character "2" at -:5:4');
    itDoesntLex("/*a*/\n2", 'Unexpected character "2" at -:2:1');
    itDoesntLex("/*a*/\n 2", 'Unexpected character "2" at -:2:2');
    itDoesntLex("/*\n", "Unexpected end of file");
    itDoesntLex("/* *", "Unexpected end of file");
    itDoesntLex("/* \tae\n\n", "Unexpected end of file");
    itDoesntLex("/*", "Unexpected end of file");
    itDoesntLex("/*", "Unexpected end of file");
    itDoesntLex("/* dsvibwi", "Unexpected end of file");
    itDoesntLex("/* cdibweic *", "Unexpected end of file");
    itDoesntLex("/* cdibweic *a", "Unexpected end of file");
    itDoesntLex("/* * /", "Unexpected end of file");
    itDoesntLex("/* *   /", "Unexpected end of file");
    itDoesntLex("/* *     /", "Unexpected end of file");
    itDoesntLex("/*/", "Unexpected end of file");
    itDoesntLex("/* /", "Unexpected end of file");
    itDoesntLex("/*     * /", "Unexpected end of file");
    itDoesntLex("/*     * * * /", "Unexpected end of file");
    itDoesntLex("/*    *a/", "Unexpected end of file");
    itLexes("/*\n*/", []);
    itLexes("/* * * * * */", []);
    itLexes("/* * ***_ */", []);
    itLexes("/**/", []);
    itLexes("/***/", []);
    itLexes("/****/", []);
    itLexes("/*****/", []);
    itLexes("/******/", []);
    itLexes("/*******/", []);
    itLexes("/********/", []);
    itLexes("/****aas ********/", []);
    itLexes("/*******a ********/", []);
    itLexes("/**********/", []);
    itLexes("/************/", []);
    itLexes("/*************/", []);
    itLexes("/**************/", []);
    itLexes("/***************/", []);
    itLexes("/*a */", []);
    itLexes("/*a \n*/", []);
    itLexes("/*a \n\n\n\n\n*/", []);
    itLexes("/**a*/", []);
    itLexes("/*a**/", []);
    itLexes("/* */", []);
    itLexes("/*a*/b/*c*/", [new token_1.IdentifierToken("b")]);
    itLexes("/* đðđ\n */u", [new token_1.IdentifierToken("u")]);
    itLexes("c/* a*/", [new token_1.IdentifierToken("c")]);
    itLexes("/* bce */a", [new token_1.IdentifierToken("a")]);
    itLexes("b/* baed */c", [new token_1.IdentifierToken("b"), new token_1.IdentifierToken("c")]);
    itLexes("/* \n\nb */a", [new token_1.IdentifierToken("a")]);
    itLexes("/* */a", [new token_1.IdentifierToken("a")]);
    itLexes("@aa bb cc", [new token_1.AnnotationToken("aa bb cc")]);
    itLexes("  @   ", [new token_1.AnnotationToken("")]);
    itLexes("@", [new token_1.AnnotationToken("")]);
    itLexes("  @  aa bb cc   ", [new token_1.AnnotationToken("aa bb cc")]);
    itLexes("  @  aa bb \n cc   ", [new token_1.AnnotationToken("aa bb"), new token_1.IdentifierToken("cc")]);
    itLexes("  @  aa bb \\   \n  cc   ", [new token_1.AnnotationToken("aa bb cc")]);
    itLexes("@\\\n  cc   ", [new token_1.AnnotationToken("cc")]);
});
